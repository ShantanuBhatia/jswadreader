/*
Before you start reading:
1. 	the Unofficial Doom Spec being referred to throughout this code
	can be found at http://www.gamers.org/dhs/helpdocs/dmsp1666.html
	It is an EXCELLENT document and I highly suggest reading it before reading this code
	I promise it'll help you understand it better

2. 	WAD files are LITTE-ENDIAN.

3. Wherever the specs refer to a " 'tag' or 'trigger' " I have stuck to the term tag.

3. 	This is a learning project, and I welcome constructive feedback. 
	I'm only here because I love Doom and I want to learn Javascript.
	And if there is something you can teach me, I'd love for you to share :)
*/

"use strict";



const fs = require('fs');
const express = require('express');
const { promisify } = require("util");

// TODO: eventually replace with command-line WAD loading
const wadPath = "./doom1.wad"; // Rip and tear! :D
const readMode = 'r'; // So we don't mess up and write over the WAD file. Easier to read than 'r'
// const dirEntrySize = 16;

const itemSizes = {
	"header": 12,
	"directoryEntry":16,
	"THING":10,
	"LINEDEF":14,
	"SIDEDEF":30,
	"VERTEX": 4,
	"SEG": 12,
	"SSECTOR":4,
	"NODE": 28,
	"SECTOR": 26,
	
}

// So we can use promises and async/await on file operations instead of getting into callback hell
const read = promisify(fs.read);
const openFile = promisify(fs.open);


/*
Every great game should have an awful ASCII art title header
This ASCII art for the heading "ShantyDoom" comtains both backtick ` and backslash \ characters.
Both of these have been be escaped w/ backslashes to render correctly.
*/
const titleText = `  _________.__                   __           ________                         
 /   _____/|  |__ _____    _____/  |_ ___.__. \\______ \\   ____   ____   _____  
 \\_____  \\ |  |  \\\\__  \\  /    \\   __<   |  |  |    |  \\ /  _ \\ /  _ \\ /     \\ 
 /        \\|   Y  \\/ __ \\|   |  \\  |  \\___  |  |    \`   (  <_> |  <_> )  Y Y  \\
/_______  /|___|  (____  /___|  /__|  / ____| /_______  /\\____/ \\____/|__|_|  /
        \\/      \\/     \\/     \\/      \\/              \\/                    \\/ `;


/*
Returns JSON of the WAD's header data
fd: file descriptor of wad file

The first twelve bytes of the WAD file contain:
four bytes of ASCII text saying if this is an IWAD or a PWAD
four bytes of a little-endian long int telling how many lumps there are
four bytes of a little-endian long int telling the offset from 
	the start of the file to the beginning of the directory
*/
const getWadHeader = async (fd) => {
	let buf = Buffer.alloc(itemSizes.header);
	let headerInfo = await read(fd, buf, 0, itemSizes.header, 0);
	//TODO: error if the file doesn't start with IWAD or PWAD
	return ({
		"wadType": headerInfo.buffer.toString('utf8', 0, 4),
		"noOfLumps": headerInfo.buffer.readUInt32LE(4),
		"dirOffset": headerInfo.buffer.readUInt32LE(8)
	});
}


/*
Returns JSON of a single lump's entry in the WAD directory. 
fd: file descriptor of wad file
offset: offset from start of file at which this directory entry starts

From the unofficial Doom Specs:
The directory has one 16-byte entry for every lump. Each entry consists
of three parts:
    (a) a long integer, the file offset to the start of the lump
    (b) a long integer, the size of the lump in bytes
    (c) an 8-byte ASCII string, the name of the lump, padded with zeros.
	  	For example, the "DEMO1" entry in hexadecimal would be
	  	(44 45 4D 4F 31 00 00 00)
*/
const readDirEntry = async (fd, entryOffset) => {
	let buf = Buffer.alloc(itemSizes.directoryEntry);
	let dirEntryObj = await read(fd, buf, 0, itemSizes.directoryEntry, entryOffset);
	let dirEntry = {
		"lumpStartOffset": dirEntryObj.buffer.readUInt32LE(0),
		"lumpSize": dirEntryObj.buffer.readUInt32LE(4),
		// the name string is zero-padded as demo'd above, and JS wants to show these zeroes as the \u0000 character
		// but we don't want that, and trim() doesn't get rid of them, so we regex them away
		"lumpName": dirEntryObj.buffer.toString('utf8', 8, 16).replace(/\0/g, '')
	}
	return dirEntry;
}


/*
Returns a array of JSON objects for all entries in the WAD directory. 
fd: file descriptor of wad file
wadHeader: JSON object created by getWadHeader() describing wad type, lump count, and directory offset.

Starting at the directory starting offset, create entries for each 16-byte directory item. 
List them and return the list.
*/
const readWadDirectory = async (fd, wadHeader) =>  {
	let indices = [...Array(wadHeader.noOfLumps).keys()];
	return Promise.all(
		indices.map( async (x) => { 
			const entry = await readDirEntry(fd, wadHeader.dirOffset+(x*itemSizes.directoryEntry));
			return entry;
		})
	);
}


/*
Returns an array of JSON objects containing all the directory entries for a given level
wadDirectory: the ordered array of JSON of the WAD's directory entries. Generated by readWadDirectory().

From the Unofficial Doom Spec Each level has eleven directory entries and ten lumps: 
	E[x]M[y] (orMAPxy in a DOOM 2 wad), THINGS, LINEDEFS, SIDEDEFS, VERTEXES, SEGS,
	SSECTORS, NODES, SECTORS, REJECT, and BLOCKMAP.
*/
 const getAllMaps =  (wadDirectory) => {
 	let levelData = [];
 	for (const [index, lump] of wadDirectory.entries()){
 		if(lump.lumpName.match(/^E[0-9]M[0-9]$/g)){
 			console.log(`loaded in level ${lump.lumpName}`);
 			levelData.push({
 				"LEVEL_entry": lump.lumpName,
 				"THINGS_entry": wadDirectory[index+1],
 				"LINEDEFS_entry": wadDirectory[index+2],
				"SIDEDEFS_entry": wadDirectory[index+3],
				"VERTEXES_entry": wadDirectory[index+4],
				"SEGS_entry": wadDirectory[index+5],
				"SSECTORS_entry": wadDirectory[index+6],
				"NODES_entry": wadDirectory[index+7],
				"SECTORS_entry": wadDirectory[index+8],
				"REJECT_entry": wadDirectory[index+9],
				"BLOCKMAP_entry": wadDirectory[index+10]
 			});
 		}
 	}

 	return levelData;
 }


/*
---------------------------------
LEVEL DATA READER FUNCTIONS START
---------------------------------

These functions return arrays of the actual data in a level's lumps, as pointed to by the level's eleven lumps
Each of these functions takes two parameters: 
	fd: file descriptor of the WAD file
	{}_entry: the relevant directory entry

They will all return arrays of JSON objects representing all the objects of that type contains in that level.
	i.e, readTHINGS returns an array of THING objects, readLINEDEFS an array of LINEDEF objects etc
*/


/*
Each THING is ten bytes long, consisiting of five short fields
TODO: add the comments explaining each of these
*/
const readTHINGS = async (fd, THINGS_entry) => {
	const ts = itemSizes.THING; // thing size
	let buf = Buffer.alloc(THINGS_entry.lumpSize);
	let thingCount = THINGS_entry.lumpSize / ts;

	console.log(`SIZE: ${THINGS_entry.lumpSize}. No of things: ${thingCount}. Starting offset: ${THINGS_entry.lumpStartOffset}`);
	// // read into the buffer the entire lump
	let thingLump = await read(fd, buf, 0, THINGS_entry.lumpSize, THINGS_entry.lumpStartOffset);

	let THINGS_arr = [];
	for(let i = 0; i < thingCount; i++){
		THINGS_arr.push({
			"x_pos": thingLump.buffer.readInt16LE((i*ts)),
			"y_pos": thingLump.buffer.readInt16LE((i*ts)+2),
			"angle": thingLump.buffer.readInt16LE((i*ts)+4),
			"type": thingLump.buffer.readInt16LE((i*ts)+6),
			"options": thingLump.buffer.readInt16LE((i*ts)+8)
		});
	}
	return THINGS_arr;
}



const readLINEDEFS = async (fd, LINEDEFS_entry) => {
	const lds = itemSizes.LINEDEF; // Linedef size
	let buf = Buffer.alloc(LINEDEFS_entry.lumpSize);
	let linedefCount = LINEDEFS_entry.lumpSize / lds;

	console.log(`SIZE: ${LINEDEFS_entry.lumpSize}. No of linedefs: ${linedefCount}. Starting offset: ${LINEDEFS_entry.lumpStartOffset}`);
	
	// read into the buffer the entire lump
	let linedefLump = await read(fd, buf, 0, LINEDEFS_entry.lumpSize, LINEDEFS_entry.lumpStartOffset);

	let LINEDEFS = [];
	for(let i = 0; i < linedefCount; i++){
		LINEDEFS.push({
			"FROM_vertex": linedefLump.buffer.readInt16LE((i*lds)),
			"TO_vertex": linedefLump.buffer.readInt16LE((i*lds)+2),
			"flags1": linedefLump.buffer.readInt16LE((i*lds)+4),
			"flags2": linedefLump.buffer.readInt16LE((i*lds)+6),
			"tag": linedefLump.buffer.readInt16LE((i*lds)+8),
			"rightSideNo": linedefLump.buffer.readInt16LE((i*lds)+10),
			"leftSideNo": linedefLump.buffer.readInt16LE((i*lds)+12)

		});
	}
	return LINEDEFS;
}


/*
Each sidedef's record is 30 bytes, comprising 2 <short> fields, then
3 <8-byte string> fields, then a final <short> field
As always, we regex away trailing \u0000 characters from strings
*/
const readSIDEDEFS = async (fd, SIDEDEFS_entry) => {
	const sds = itemSizes.SIDEDEF; // Sidedef size
	let buf = Buffer.alloc(SIDEDEFS_entry.lumpSize);
	let sidedefCount = SIDEDEFS_entry.lumpSize / sds;

	console.log(`SIZE: ${SIDEDEFS_entry.lumpSize}. No of sidedefs: ${sidedefCount}. Starting offset: ${SIDEDEFS_entry.lumpStartOffset}`);
	
	// read into the buffer the entire lump
	let sidedefLump = await read(fd, buf, 0, SIDEDEFS_entry.lumpSize, SIDEDEFS_entry.lumpStartOffset);

	let SIDEDEFS = [];
	for(let i = 0; i < sidedefCount; i++){
		SIDEDEFS.push({
			"x_offset": sidedefLump.buffer.readInt16LE((i*sds)),
			"y_offset": sidedefLump.buffer.readInt16LE((i*sds)+2),
			"upper_tex_name": sidedefLump.buffer.toString('utf8', (i*sds)+4, (i*sds)+12).replace(/\0/g, ''), 
			"lower_tex_name": sidedefLump.buffer.toString('utf8', (i*sds)+12, (i*sds)+20).replace(/\0/g, ''),
			"middle_tex_name": sidedefLump.buffer.toString('utf8', (i*sds)+20, (i*sds)+28).replace(/\0/g, ''),
			"facing_sector": sidedefLump.buffer.readInt16LE((i*sds)+28),
		});
	}
	return SIDEDEFS;



}

/*
Dead simple: a vertex is two shorts, an x and a y
*/
const readVERTEXES = async (fd, VERTEXES_entry) => {
	const vs = itemSizes.VERTEX; // vertex size
	let buf = Buffer.alloc(VERTEXES_entry.lumpSize);
	let vertexCount = VERTEXES_entry.lumpSize / vs;

	console.log(`SIZE: ${VERTEXES_entry.lumpSize}. No of vertexes: ${vertexCount}. Starting offset: ${VERTEXES_entry.lumpStartOffset}`);
	
	// read into the buffer the entire lump
	let vertexLump = await read(fd, buf, 0, VERTEXES_entry.lumpSize, VERTEXES_entry.lumpStartOffset);

	let VERTEXES = [];
	for(let i = 0; i < vertexCount; i++){
		VERTEXES.push({
			"x": vertexLump.buffer.readInt16LE((i*vs)),
			"y": vertexLump.buffer.readInt16LE((i*vs)+2)
		});
	}
	return VERTEXES;
}

const readSEGS = async (fd, SEGS_entry) => {
	const ss = itemSizes.SEG;
	let buf = Buffer.alloc(SEGS_entry.lumpSize);
	let itemCount = SEGS_entry.lumpSize / ss;

	console.log(`SIZE: ${SEGS_entry.lumpSize}. No of SEGS: ${itemCount}. Starting offset: ${SEGS_entry.lumpStartOffset}`);
	
	// read into the buffer the entire lump
	let segsLump = await read(fd, buf, 0, SEGS_entry.lumpSize, SEGS_entry.lumpStartOffset);
	let SEGS = [];
	for(let i = 0; i < itemCount; i++){
		SEGS.push({
			"start_VERTEX": segsLump.buffer.readInt16LE((i*ss)),
			"end_VERTEX": segsLump.buffer.readInt16LE((i*ss)+2),
			"angle": segsLump.buffer.readInt16LE((i*ss)+4),
			"LINEDEF": segsLump.buffer.readInt16LE((i*ss)+6),
			"direction": segsLump.buffer.readInt16LE((i*ss)+8),
			"offset": segsLump.buffer.readInt16LE((i*ss)+10)
		});
	}
	// console.log(SEGS.length);
	return SEGS;
}

const readSSECTORS = async (fd, SSECTORS_entry) => {
	const ss = itemSizes.SSECTOR;
	let buf = Buffer.alloc(SSECTORS_entry.lumpSize);
	let itemCount = SSECTORS_entry.lumpSize / ss;

	console.log(`SIZE: ${SSECTORS_entry.lumpSize}. No of SSECTORS: ${itemCount}. Starting offset: ${SSECTORS_entry.lumpStartOffset}`);
	
	// read into the buffer the entire lump
	let ssectorsLump = await read(fd, buf, 0, SSECTORS_entry.lumpSize, SSECTORS_entry.lumpStartOffset);
	let SSECTORS = [];
	for(let i = 0; i < itemCount; i++){
		SSECTORS.push({
			"SEGS_count": ssectorsLump.buffer.readInt16LE((i*ss)),
			"starting_SEG": ssectorsLump.buffer.readInt16LE((i*ss)+2),

		});
	}
	// console.log(SEGS.length);
	return SSECTORS;
}

const readNODES = async (fd, NODES_entry) => {
	const ns = itemSizes.NODE;
	let buf = Buffer.alloc(NODES_entry.lumpSize);
	let itemCount = NODES_entry.lumpSize / ns;

	console.log(`SIZE: ${NODES_entry.lumpSize}. No of SSECTORS: ${itemCount}. Starting offset: ${NODES_entry.lumpStartOffset}`);
	
	// read into the buffer the entire lump
	let nodesLump = await read(fd, buf, 0, NODES_entry.lumpSize, NODES_entry.lumpStartOffset);
	let NODES = [];
	for(let i = 0; i < itemCount; i++){
		NODES.push({
			"paritionline_start_x": nodesLump.buffer.readInt16LE((i*ns)),
			"paritionline_start_y": nodesLump.buffer.readInt16LE((i*ns)+2),
			"dx": nodesLump.buffer.readInt16LE((i*ns)+4),
			"dy": nodesLump.buffer.readInt16LE((i*ns)+6),
			"right_bb_y_ub": nodesLump.buffer.readInt16LE((i*ns)+8),
			"right_bb_y_lb": nodesLump.buffer.readInt16LE((i*ns)+10),
			"right_bb_x_lb": nodesLump.buffer.readInt16LE((i*ns)+12),
			"right_bb_x_ub": nodesLump.buffer.readInt16LE((i*ns)+14),
			"left_bb_y_ub": nodesLump.buffer.readInt16LE((i*ns)+16),
			"left_bb_y_lb": nodesLump.buffer.readInt16LE((i*ns)+18),
			"left_bb_x_lb": nodesLump.buffer.readInt16LE((i*ns)+20),
			"left_bb_x_ub": nodesLump.buffer.readInt16LE((i*ns)+22),
			"right_child_node": nodesLump.buffer.readInt16LE((i*ns)+24),
			"left_child_node": nodesLump.buffer.readInt16LE((i*ns)+26),

		});
	}
	// console.log(SEGS.length);
	return NODES;
}

const readSECTORS = async (fd, SECTORS_entry) => {
	const ss = itemSizes.SECTOR;
	let buf = Buffer.alloc(SECTORS_entry.lumpSize);
	let itemCount = SECTORS_entry.lumpSize / ss;

	console.log(`SIZE: ${SECTORS_entry.lumpSize}. No of SECTORS: ${itemCount}. Starting offset: ${SECTORS_entry.lumpStartOffset}`);
	
	// read into the buffer the entire lump
	let nodesLump = await read(fd, buf, 0, SECTORS_entry.lumpSize, SECTORS_entry.lumpStartOffset);
	let SECTORS = [];
	for(let i = 0; i < itemCount; i++){
		SECTORS.push({
			"floor_height": nodesLump.buffer.readInt16LE((i*ss)),
			"ceiling_height": nodesLump.buffer.readInt16LE((i*ss)+2),
			"floor_tex_name": nodesLump.buffer.toString('utf8', (i*ss)+4, (i*ss)+12).replace(/\0/g, ''), 
			"ceiling_tex_name": nodesLump.buffer.toString('utf8', (i*ss)+12, (i*ss)+20).replace(/\0/g, ''),
			"light_level": nodesLump.buffer.readInt16LE((i*ss)+20),
			"special_sector": nodesLump.buffer.readInt16LE((i*ss)+22),
			"tag_number": nodesLump.buffer.readInt16LE((i*ss)+22),

		});
	}
	// cossole.log(SEGS.length);
	return SECTORS;
}

const readREJECT = async (fd, REJECT_entry, SECTORS_entry, BLOCKMAP_entry) => {
	const sectorCount = SECTORS_entry.lumpSize / itemSizes.SECTOR;
	
	let indices = [...Array(sectorCount).keys()];
	let REJECT_calculatedSize = ((sectorCount*sectorCount) % 8 == 0) ? (sectorCount*sectorCount)/8 : (Math.floor((sectorCount*sectorCount)/8)) + 1;

	// let REJECT_calculatedSize = (Math.floor((sectorCount*sectorCount)/8) == ((sectorCount*sectorCount)/8)? (Math.floor((sectorCount*sectorCount)/8)) : (Math.floor((sectorCount*sectorCount)/8) + 1);

	
	console.log(`expected REJECT size: ${REJECT_calculatedSize}. Actual REJECT size: ${BLOCKMAP_entry.lumpStartOffset - REJECT_entry.lumpStartOffset}`);
	
	let BLOCKMAP = Array(sectorCount).fill(0,0,sectorCount).map((item)=>{return Array(sectorCount).fill(0,0,sectorCount)});


	console.log(BLOCKMAP['5'].length);
	// let blockmapLump = await read(fd, buf, 0, BLOCKMAP_entry.lumpSize, BLOCKMAP_entry.lumpStartOffset);
	return 5;
}


/*
--------------------------------
LEVEL DATA READER FUNCTIONS STOP
--------------------------------
*/




const constructLevel = async (fd, levelJSON) => {
	let levelThings = await readTHINGS(fd, levelJSON.THINGS_entry);
	// console.log(JSON.stringify(levelThings[0]));
	let levelLinedefs = await readLINEDEFS(fd, levelJSON.LINEDEFS_entry);
	// console.log(JSON.stringify(levelLinedefs[0]));
	let levelSidedefs = await readSIDEDEFS(fd, levelJSON.SIDEDEFS_entry);
	// console.log(JSON.stringify(levelSidedefs[0]));
	let levelVertexes = await readVERTEXES(fd, levelJSON.VERTEXES_entry);
	// console.log(JSON.stringify(levelVertexes[0]));
	let levelSegs = await readSEGS(fd, levelJSON.SEGS_entry);
	// console.log(JSON.stringify(levelSegs[0]));
	let levelSsectors = await readSSECTORS(fd, levelJSON.SSECTORS_entry);
	// console.log(JSON.stringify(levelSsectors[0]));
	let levelNodes = await readNODES(fd, levelJSON.NODES_entry);
	// console.log(JSON.stringify(levelNodes[6]));
	let levelSectors = await readSECTORS(fd, levelJSON.SECTORS_entry);
	// console.log(JSON.stringify(levelSectors[10]));
	let tmp = await readREJECT(fd, levelJSON.REJECT_entry, levelJSON.SECTORS_entry, levelJSON.BLOCKMAP_entry);
}





// TODO: reject running if the file provided is not a WAD
const main = async () => {
	console.log(titleText);
	console.log("Doom! In Javascript! By Shanty!");
	let fd = await openFile(wadPath, readMode);
	console.log(`WAD file has been opened at fd ${fd}`);
	let doomWadHeader = await getWadHeader(fd);
	console.log(JSON.stringify(doomWadHeader));
	let x = await readWadDirectory(fd, doomWadHeader);
	console.log(JSON.stringify(x[2]));
	let y = getAllMaps(x);
	let e1m2 = y[1]
	constructLevel(fd, e1m2);

}


main();